---
title: 'W271 Lab 2: CO2 1997'
geometry: margin=1in
output:
  github_document: default
---

```{r load packages, echo = FALSE, message = FALSE}
library(tidyverse)
library(tsibble)
library(latex2exp)
theme_set(theme_minimal())
knitr::opts_chunk$set(dpi=1000)

# additional packages
library(dplyr)
library(Hmisc)
library(patchwork)
library(forecast)
library(stargazer)
library(gridExtra)
```


## (3 points) Task 0a: Introduction 
Observed by Charles D. Keeling in 1960, there is a systematic variation with season and latitude in the concentration and isotopic abundance of atmospheric carbon dioxide ($CO_2$). Here, we are interested in two questions. First, what is the overall trend and seasonality of the atmospheric $CO_2$ level? And second, whether or not atmospheric $CO_2$ level can be model effectively thorugh a combination of de-trending, smoothing averages, and ARIMA? Addressing these two issues will provide us a better understanding of $CO_2$ build up over time and to forecast for future effect. 

## (3 points) Task 1a: CO2 data

```{r}
# basic information about the data
print(sum(is.na(co2)))
print(start(co2))
print(end(co2))
```
> The data starts from 1959 Jan and ends in 1997 Dec. There are no missing values.

```{r}
tsibble::as_tsibble(co2) %>%
  ggplot() + 
  aes(x=index, y=value) + 
  geom_line(color = 'steelblue') +
  labs(
    title = TeX(r'(Monthly Mean $CO_2$)'),
    subtitle = 'The "Keeling Curve"',
    x = 'Month and Year',
    y = TeX(r'($CO_2$ parts per million)')
  )
```


```{r}
# TODO: use additive or multiplicative?
dcmp <- decompose(co2, "additive")
plot(dcmp)
```
> trend: strong positive linear trend across years
> irregular elements: Nothing in the random plot. The data oscilate around 0.
> seasonality: strong seasonality - will explore details in next plot

```{r}
boxplot(co2~cycle(co2, xlab="Month", ylab = "CO2 (ppm)", main = "Monthly Mean CO2"))
```
> seasonal: Lowest in October and highest in May 
> CO2 is highest in May and lowest in October. 
> May is warmer, people are more active outside and travel more, which can generate more carbon emissions.


## (3 points) Task 2a: Linear time trend model

```{r}
# Fit a linear time trend model examine the characteristics of the residuals
mod.lm1 = lm(co2 ~ time(co2))
summary(mod.lm1)
plot(mod.lm1, which=c(1,1))
```
> residuals for linear model forms a curved line

```{r}
# quadratic time trend model.
mod.lm2 = lm(co2 ~ time(co2) + I(time(co2)^2))
summary(mod.lm2)
plot(mod.lm2, which=c(1,1))
```
> residuals for quadratic model is consistently closer to 0. Quadratic was better captured the trend.


```{r}
# Discuss whether a logarithmic transformation of the data would be appropriate. 
# Refer to LS7
par(mfrow=c(1,2))
plot(log(co2), col='blue')
plot(co2, col='red')
```
> it's exactly the same except for scale, so we do not need to apply a log transformation for this data. Original trend already has a clear linear trend, and so does not benefit from log transformation.
> A multiplicative model may be more appropriate if the seasonal effect increases as the trend increase. However, that is not the case for this data.

```{r}
# Fit a polynomial time trend model that incorporates seasonal dummy variables, and use this model to generate forecasts to the year 2020. 


# function to be AIC and BIC scores
eval_results = function(models){
# calculate from models
aic_results = lapply(models, function(model) AIC(model))
bic_results = lapply(models, function(model) BIC(model))
# flatten list
aic_results = unlist(aic_results, recursive = TRUE, use.names = TRUE)
bic_results = unlist(bic_results, recursive = TRUE, use.names = TRUE)
results = data.frame(modelname = names(models), aic=aic_results, bic=bic_results)
return(results)
}

# fine-tune polynomial model
# TODO: replace poly_season with dummy season variable - refer to LS7
# TODO: break up into two plots. Fix tdeg and change sdeg instead of doing all combinations.
models=list()
for (tdeg in 1:5){
  for (sdeg in 1:5){
    fit <- tslm(co2 ~ poly(trend,tdeg) + poly(season, sdeg))
    models[[paste(tdeg,sdeg,sep='_')]]=fit
  }
}

results = eval_results(models)
# plot AIC/BIC of polynomial models
results %>%
    gather(key = "name", value = "value", aic, bic) %>%
    ggplot(aes(x = modelname, y = value, colour=name, group=name)) +
    geom_point() +
    geom_line() +
    xlab("Number of Parameters") +
    ylab("AIC/BIC")
# based on graph, trend degree = 3 and season degree = 4 looks the best
```
> trend degree = 3 seems best. No significant improvement after that.


```{r} 

mod.poly <- tslm(co2 ~ poly(trend,3) + poly(season,4))
summary(mod.poly)
par(mfrow = c(2, 2))
plot(mod.poly$residuals)
plot(forecast::forecast(mod.poly, h=20*12))

```
> polynomial time trend that incorporates a seaosnal dummy variable was able to capture the linear and seasonal trend when forecasted to 2020. There's a slight curve at the 2020 tail of the trend due to the 3rd degree polynomial.

## (3 points) Task 3a: ARIMA times series model

> For the ARIMA model, we can conjecture the following parameters:
> p: the number of lag observations in the model, also known as the lag order. Inspect PACF plot.
> d: the number of times the raw observations are differenced; also known as the degree of differencing. 
> q: the size of the moving average window, also known as the order of the moving average. ACF tells how many MA terms are required to remove any autocorrelation in the stationarized series.

```{r, echo=F, message=F}
# first step, no differencing

co2 %>% ggtsdisplay(main="")

```
> time series plot: strong positive correlation
> ACF: strong positive correlation with slight bumps suggest seasonality, which makes sense based on our EDA. ACF is positive for all the lags, so the series needs further differencing.
> PACF: suggests that this is an AR(2) model.

```{r}
# 1st DIFFERENCING
diff(co2) %>% ggtsdisplay(main="")
```
> The right order of differencing is the minimum differencing required to get a near-stationary series which roams around a defined mean and the ACF plot reaches to zero fairly quick. You need differencing only if the series is non-stationary. Else, no differencing is needed, that is, d=0.
The origin data are clearly non-stationary, as the series has a strong positive correlation. Consequently, we will take a first difference of the data. The differenced data are shown above. These look stationary, and so we will not consider further differences.
> TODO - how to explain plots?
> ACF: ACF shows a periodic seasonality to it. This means that we need to apply some moving average component to remove the seasonality.
> PACF: Potentially ARIMA(3).
> Suggesting ARIMA(2,1,3) or ARIMA(1,1,2)


```{r}
# TODO - check order parameter, and add other necessary parameters
# TODO - how to manually determine arima parameters? - LS7
# AUTO ARIMA
mod.arima = auto.arima(co2)
summary(mod.arima)
arima_pred <- forecast::forecast(mod.arima, level=c(95), h=22*12)
plot(arima_pred)

# SELF-DETERMINED parameters
order= c(1,1,2)
mod.arima = arima(co2, order=order, seasonal=list(order=order,period=NA))
summary(mod.arima)
arima_pred <- forecast::forecast(mod.arima, level=c(95), h=22*12)
plot(arima_pred)

```


## (3 points) Task 4a: Forecast atmospheric CO2 growth 
```{r, echo=F}
arima_pred <- forecast::forecast(mod.arima, level=c(95), h=110*12)
plot(arima_pred)
abline(h = 420, col='red')
abline(h = 500, col='red')
```


```{r}

# TODO: double check numbers
lower = data.frame(arima_pred) %>%
  filter(Point.Forecast >= 420) %>%
  head(1)
upper = data.frame(arima_pred) %>%
  filter(Point.Forecast <= 500) %>%
  tail(1)

# TODO: filter by index of dataframe
level2100 = data.frame(arima_pred) %>%
  filter(Point.x <= 2100) %>%
  tail(1)


co2_bounds = rbind(lower, upper, level2100)
co2_bounds
```

