---
title: 'W271 Lab 2: CO2 1997'
author: Ken Trinh, Lisa Wu, Ray Cao, Sophie Yeh
geometry: margin=1in
output:
  bookdown::pdf_document2: default
---

```{r load packages, echo = FALSE, message = FALSE, warning=FALSE}
library(tidyverse)
library(tsibble)
library(latex2exp)
theme_set(theme_minimal())
knitr::opts_chunk$set(dpi = 1000)

# additional packages
library(dplyr)
library(Hmisc)
library(patchwork)
library(forecast)
library(stargazer)
library(gridExtra)

library(lubridate)
library(zoo)
library(fable)
library(feasts)
library(forecast)
library(tseries)
library(plyr)
library(ggplot2)
library(ggthemes)
library(scales)
library(gridExtra)
library(tidyverse)
library(magrittr)
library(sandwich)
library(lmtest)
library(blsR)
```

## (3 points) Task 0a: Introduction

If you are concerned about global warming (or wonder whether this is true or not), you may have heard about the "Keeling Curve" which is named after the scientist Charles David Kneeling. Kneeling started measuring and monitoring the accumulation of carbon dioxide ($CO_2$) in the atmosphere in 1958. Many scientists credit the Keeling curve with first bringing our attention to the current increase of $CO_2$ in the atmosphere. The one key question in people's minds is whether $CO_2$ will continue to go up and at what speed, over the next few decades. The answer to this question is critical to our policy makers and environmentalists. The forecast $CO_2$ results will help them evaluate how concerned they should be and what actions to take to minimize the consequences. In order to answer this question, we will conduct the study of the $CO_2$ data set and develop a model(s) to forecast $CO_2$.

## (3 points) Task 1a: CO2 data
The CO2 data, tracking the atmospheric $CO_2$ level in part per million by volumne (ppmv), was measured continuously at the Mauna Loa Observatory in Hawaii since 1958. This data has 468 monthly observations, from January 1958 to December 1997 (no missing data). Prior to this effort, measurements of $CO_2$ concentrations had been taken on an ad hoc basis at a variety of locations. Keeling created a frequent and consistent measurement framework of $CO_2$. Keeling and his collaborators measured the incoming ocean breeze above the thermal inversion layer to minimize local contamination from volcanic vents. The data were normalized to remove any influence from local contamination. 

```{r basic-information, echo = FALSE, message = FALSE, warning = FALSE, include=FALSE}
# basic information about the data
print(sum(is.na(co2))) # check for NA data
print(start(co2)) # start of the time series
print(end(co2)) # end of the time series
summary(co2)
glimpse(co2)
```


```{r CO2-ETSDA, echo = FALSE, warning=FALSE, message=FALSE, fig.align='center', out.width="65%", fig.cap="Atmospheric CO2 Level Time Series Overview"}
co2_enhanced <- co2 %>%
  as_tsibble() %>%
  mutate(
    # Difference in route between years
    annual_growth = (value - lag(value, n = 12)) / lag(value, n = 12) * 100,
    log_value = log(value)
  )

# plot the annualized growth rate
p_3 <- co2_enhanced %>%
  ggplot() +
  aes(x = index, y = annual_growth) +
  geom_line(color = "steelblue") + geom_smooth(method = "loess", color='black') +
  labs(
    title = TeX(r"(Annualized Growth $CO_2$)"),
    subtitle = 'The "Keeling Curve"',
    x = "Month and Year",
    y = TeX(r"($CO_2$ Annualized Growth Rate)")
  ) +
  theme(plot.title = element_text(size = 10))

# plot the histogram
p_4 <- co2_enhanced %>%
  ggplot(aes(x = value)) +
  geom_histogram(binwidth = 1) +
  labs(title = TeX(r"(Histogram Monthly Mean $CO_2$)"), col = " blue") +
  xlab("Monthly Mean") +
  theme(plot.title = element_text(size = 10))
# scale_x_continuous(limits = c(0, 16), breaks = seq(1,16,2))


# Use additive method in STL decomposition
dcmp_add <- co2_enhanced %>%
  model(stl = STL(value))

# plot of time series
p_5_add <- components(dcmp_add) %>%
  as_tsibble() %>%
  autoplot(value, colour = "gray") +
  geom_line(aes(y = trend), colour = "#D55E00") +
  labs(
    y = TeX(r"($CO_2$ Annualized Growth Rate)"),
    x = "Month and Year",
    title = "Monthly Mean CO2"
  ) +
  theme(plot.title = element_text(size = 10))

# plot the components
p_6_add <- components(dcmp_add) %>%
  autoplot() + theme(plot.title = element_text(size = 10))

par(mar = c(4, 4, 0.1, 0.1)) 
(p_5_add | p_3) / (p_4 | p_6_add)
```

```{r, include=FALSE}
mean_growth_rate <- round(mean(co2_enhanced$annual_growth, na.rm=TRUE),2)
```
Figure \@ref(fig:CO2-ETSDA) shows that $CO_2$ level is trending up over time, with seasonal variability. The annual growth rate is mostly in the range of 0-0.75%, with a modest upward trend. The long run average of the annual growth rates is $`r mean_growth_rate`$%.  Since $CO_2$ is a greenhouse gas, the increasing trend has significant implications for global warming. From the histogram chart, we observed that the $CO_2$ levels are not normally distributed, ranging from 310 to 370 ppmv. There is no extreme outliers in this data set. Furthermore, the $CO_2$ Decomposition graph shows the upward trend, seasonal effect and irregular components of the data set.  

```{r boxplot, echo=FALSE, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center', out.width="55%", fig.cap="Seasonality CO2 Level Monthly Distribution", include=FALSE}
# box plot
box <- boxplot(co2 ~ cycle(co2, xlab = "Month", ylab = "CO2 (ppmv)", main = "Monthly Mean CO2"))
max_min_diff <- max(box$stats[3, ]) - min(box$stats[3, ])
```
In our analysis, we noted that the maximum level occurs in May and then decreases during the warm seasons as new plant growth takes $CO_2$ out of the air. After reaching a minimum in October, as plants die off in the cold weather, $CO_2$ is released back into the atmosphere. The difference between the peak and trough monthly averages is $`r max_min_diff`$ ppmv.  

```{r logarithmic-transformation, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center', out.width="65%", fig.cap="CO2 level regular versus logarithmic transformation", include=FALSE}
# Discuss whether a logarithmic transformation of the data would be appropriate.
# Refer to LS7
par(mfrow = c(1, 2))
plot(log(co2), col = "blue")
plot(co2, col = "red")
```

## (3 points) Task 2a: Linear time trend model

As shown in Figure \@ref(fig:CO2-ETSDA) of the $CO_2$ Data section, the $CO_2$ time series data set follows closely to a linear trend line, with a slight curvature. The annual growth rates are range-bound, with a modest upward trend. We don't see a strong sign of exponential growth or increased variance over time. Hence we don`t think it is necessary to perform a logarithmic transformation for this data set.

We will first develop a linear trend model, with time as the explanatory variable. Reported as Model (1) in Table 1, this model has an intercept term and a positive slope of 1.3. Both coefficients are statistically significant, with p-value less than 0.001. The model residuals, shown in Figure \@ref(fig:linear-quadratic-model-plot) (left), are curved, which violates the assumption of independent and identically distributed residuals with zero mean expectation. Variance increases as the fitted values increase, which violates the homoskedasticity assumption of classical linear model. Clearly this simple model failed to sufficiently capture the data characteristics.

We then evaluated the quadratic model by adding the quadratic term of time. See Model (2) results in Table 1. The right plot in Figure \@ref(fig:linear-quadratic-model-plot) also shows a curved residuals line. Variance still shows some level of heteroskedasticity. This model also does not adequately capture the data characteristics.

```{r linear-and-quadratic-models, message=FALSE, warning=FALSE}
mod.lm1 <- lm(co2 ~ time(co2))
mod.lm2 <- lm(co2 ~ time(co2) + I(time(co2)^2))
```

```{r linear-model-stargazer, echo=FALSE, results = "asis",  message = FALSE, echo=FALSE, warning=FALSE}
stargazer(mod.lm1, mod.lm2,
  header = FALSE,
  type = "latex", omit.stat = c("f", "ser"),
  covariate.labels = c("linear time", "quadratic time", "(Intercept)"),
  report = ("vc*p"),
  star.cutoffs = c(0.05, 0.01, 0.001),
  title = "Estimated Atmospheric CO2 Level",
  dep.var.caption = "Output Variable: CO2 Level in ppmv",
  dep.var.labels = "",
  column.sep.width = "-8pt"
)
```

```{r linear-quadratic-model-plot, warning=FALSE, message=FALSE, fig.align='center', out.width="50%", fig.cap="Residuals vs Fitted Plots: Linear Model (Left) Quadratic Model (Right)", echo=FALSE}
# plot the residuals

lm_plot <- ggplot(mod.lm1, aes(.fitted, .resid)) +
  geom_point() +
  stat_smooth() +
  xlab("Fitted Values") +
  ylab("Residuals") +
  labs(title = "Linear Model Fitted vs Residuals Plot") +
  theme(plot.title = element_text(size = 10)) +
  ylim(-5, 5)

quard_plot <- ggplot(mod.lm2, aes(.fitted, .resid)) +
  geom_point() +
  stat_smooth() +
  xlab("Fitted Values") +
  ylab("Residuals") +
  labs(title = "Quardratic Model Fitted vs Residuals Plot") +
  theme(plot.title = element_text(size = 10)) +
  ylim(-5, 5)

par(mar = c(2, 2, 2, 2)) 
lm_plot | quard_plot
```

Finally we fitted a polynomial time trend model which incorporated seasonal dummy variables. We used the goodness-of-fit information criterion to select the polynomial degree that optimizes the model fit. The three goodness-of-fit metrics are AIC, AICc and BIC. Lower AIC, AICc and BIC score indicates better model performance. Generally, BIC has a larger penalty for models with more parameters and therefore selects sparser models with fewer parameters, compared to AIC and AICc. We ran both AIC and BIC and displayed the result in Figure \@ref(fig:polynomial-trend-seasonality).  We use a range of 1 to 5 polynomial degrees for the trend variable and donâ€™t recommend trying higher polynomial degrees to avoid over-fitting. This result shows that 3 is the optimal degree with the lowest AIC and BIC score. 

```{r polynomial-trend-seasonality, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center', out.width="50%", fig.cap="Polynomial trends selection using information criterions"}
# Fit a polynomial time trend model that incorporates seasonal dummy variables
# use this model to generate forecasts to the year 2020.

# function to be AIC and BIC scores
eval_results <- function(models) {
  # calculate from models
  aic_results <- lapply(models, function(model) AIC(model))
  bic_results <- lapply(models, function(model) BIC(model))
  # flatten list
  aic_results <- unlist(aic_results, recursive = TRUE, use.names = TRUE)
  bic_results <- unlist(bic_results, recursive = TRUE, use.names = TRUE)
  results <- data.frame(modelname = names(models), aic = aic_results, bic = bic_results)
  return(results)
}

# optimize polynomial model
models <- list()
for (tdeg in 1:5) {
  fit <- tslm(co2 ~ poly(trend, tdeg) + season)
  models[[paste(tdeg, sep = "_")]] <- fit
  # }
}
results <- eval_results(models)
# plot AIC/BIC of polynomial models
bic.plt <- results %>%
  gather(key = "name", value = "value", aic, bic) %>%
  ggplot(aes(x = modelname, y = value, colour = name, group = name)) +
  geom_point() +
  geom_line() +
  xlab("Number of Parameters") +
  ylab("AIC/BIC")
# based on graph, trend degree = 3 and season degree = 4 looks the best

par(mar = c(2, 2, 2, 2)) 
bic.plt
```


```{r polynomial-model, message = FALSE, warning=FALSE}
mod.poly <- tslm(co2 ~ poly(trend, 3) + season)
```

```{r polynomial-model-stargazer, echo=FALSE, results = "asis", message = FALSE, warning=FALSE, include=FALSE}
stargazer(summary(mod.poly)$coefficients,
  header = FALSE,
  type = "latex", omit.stat = c("f", "ser"),
  report = ("vc*p"),
  star.cutoffs = c(0.05, 0.01, 0.001),
  title = "Estimated Atmospheric CO2 Level",
  dep.var.caption = "Output Variable: CO2 Level in ppmv",
  dep.var.labels = "",
  column.sep.width = "-8pt"
)
```

```{r polynomial-diagnostic-forecast, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center', out.width="50%", fig.cap="Polynomial Trend And Seasonality Forecast", include=FALSE}
par(mfrow = c(2, 2))
plot(mod.poly$residuals)
plot(forecast::forecast(mod.poly, h = 20 * 12))
```

Once fitted, we performed diagnosis on the residuals. We noted that the residuals have significant positive autocorrelation, which will underestimate the standard errors.  Variance is not constant as well. Classical linear regression model assumptions are violated. While further improvements are necessary, we will use the fitted polynomial model to forecast the $CO_2$ level through 2020 (Figure \@ref(fig:polynomial-forecast)). The forecast results capture the trend and seasonal effect well through 2020. After 2020, the forecast $CO_2$ level trends down due to the 3rd degree polynomial effect.

```{r polynomial-diagnostic, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE, fig.align='center', out.width="50%", fig.cap="Polynomial Residuals Diagnostic Plots"}
# set test=FALSE so we don't need to print out the Breusch-Godfrey(BG) test result. Set Test=True to print out the BG results
par(mar = c(1, 1, 1, 1)) 
checkresiduals(mod.poly, test = FALSE)
```


```{r polynomial-forecast, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center', out.width="50%", fig.cap="Linear model with polynomial trend and dummy seasonality forecast"}
# forecast to 2030 December
par(mar = c(2,2,2,2)) 
fit_2030 <- forecast::forecast(mod.poly, level = 95, h = 33 * 12, robust = TRUE)
plot(fit_2030)
abline(v = 2020, col = "red")
abline(v = 2030, col = "red")
```


## (3 points) Task 3a: ARIMA times series model

We will fit a ARIMA model for this data set. This model has three parameters (p, d, q). p stands for the number of lag terms, d stands for the number of times the raw observations are differenced, and q stands for the size of the moving average (MA) window. Typically for ARIMA, PACF plot indicates the lag order while ACF indicates the MA terms needed to transform the data to a stationary time series.

As discussed earlier, this time series has a strong positive trend and seasonal effect and is non-stationary. Figure \@ref(fig:first-order-diff) shows that, after taking a first difference of the data, the resulting time series appears to oscillate around 0. To ensure that it is stationary, we applied the Augmented Dickey-Fuller test, which returns a significant p-value less than 0.05. Thus, we have sufficient evidence to reject the null hypothesis and believe that the time series after the first differencing is stationary. The ACF plot show significant cyclic lags due to seasonality, with no signs of dampening. The PACF plot has significant lags in the first 12 months which dampen after.

```{r ts-analysis, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center', out.width="50%", fig.cap="CO2 Level ACF and PACF plots", include=FALSE}
# first step, no differencing
co2 %>% ggtsdisplay(main = "")
```

```{r first-order-diff, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center', out.width="50%", fig.cap="CO2 Level 1st order differencing ACF and PACF plots"}
# 1st DIFFERENCING
diff(co2) %>% ggtsdisplay(main = "")
```

```{r adf-test, warning = FALSE, echo=FALSE}
adf.test(diff(co2))
```

Because the ACF has persistent significant lags while the PACF has dampening oscillations, the data leans towards a mixed of AR and MA process, with the first differencing order. Hence the ARIMA(p,1,q) model will be the most appropriate model form. We will use an iterative process to select the optimal AR and MA parameters based on the goodness-of-fit information criterion (AIC/AICc/BIC). We chose to use BIC for this process, as BIC has a larger penalty for models with more parameters and tends to select sparser models with fewer parameters compared to AIC and AICc.

```{r model-fitting, results = "asis", warning = FALSE}
# use auto arima and BIC to optimize AR and MA terms
mod.arima <- auto.arima(co2, d = 1, ic = "bic", trace = FALSE, seasonal = TRUE)
knitr::kable(mod.arima$coef,  col.names= "coefs", "latex")
```

```{r alternative arima selection process, echo=FALSE, include=FALSE}
# arima_model <-  co2_enhanced %>%
#   model(arima = ARIMA(value ~ 1 + pdq(0:5, 0:2, 0:5) + PDQ(0:5, 0:2, 0:5),
#                       ic = 'bic', stepwise=F, greedy=F,
#                       trace=TRUE))
#
# arima_model %>%
#   report()
# this process selects Model: ARIMA(1,0,1)(4,1,0)[12] w/ drift

# arima_model  %>%
#   select(arima) %>%
#   gg_tsresiduals()
```

The final model is estimated to be ARIMA(0,1,1)(1,1,2)[12] with a BIC of 201.78. We analyzed the model residuals to evaluate model performance. Figure \@ref(fig:arima-model-residuals) shows that the residuals oscillates around 0. The ACF plot shows no significant autocorrelation, like a white noise process. The Ljung-Box test returns a large p-value of 0.3406, suggesting a very strong evidence that the residuals are stationary. Since the model residuals are stationary, we will use the model to forecast atmospheric CO2 level to 2022 (Figure \@ref(fig:ARIMA-forecast)). Noted that after 2010, the forecast starts to have a wider confidence interval.

```{r arima-model-residuals, echo = FALSE, message = FALSE, warning = FALSE, fig.align='center', out.width="50%", fig.cap="ARIMA(0,1,1)(1,1,2)[12] CO2 Level residuals"}
checkresiduals(mod.arima) 
```

```{r ARIMA-forecast, message=FALSE, warning=FALSE ,fig.align='center', out.width="50%", fig.cap="ARIMA(0,1,1)(1,1,2)[12] CO2 level 2022 forecast"}
arima_pred <- forecast::forecast(mod.arima, level = c(95), h = 25 * 12)
plot(arima_pred)
```


## (3 points) Task 4a: Forecast atmospheric CO2 growth

We used the ARIMA model to forecast accumulated atmospheric $CO_2$ levels through 2100, to gauge when $CO_2$ levels will hit certain target. Our model forecasts that the atmospheric $CO_2$ level will reach 420 ppm by May 2031 and 500 ppm by Oct 2086. By Jan 2100, CO2 levels will reach 524 ppm. We are not confident about these predictions, because the lower bound of the confidence interval has plateaued at approximately 390 ppm while the upper bound continues to grow higher. While the forecast has a wide confidence interval, the actual level accumulation could dramatically exceed the expected forecast level. Since $CO_2$ is a green house gas, any actions that we take now could prevent drastic damages in the future.

```{r ARIMA-distant-future-forecast, echo=FALSE, message=FALSE, warning=FALSE ,fig.align='center', out.width="50%", fig.cap="ARIMA(0,1,1)(1,1,2)[12] CO2 Level distant future forecast", include=FALSE}
arima_pred <- forecast::forecast(mod.arima, level = c(95), h = 110 * 12)
plot(arima_pred)
abline(h = 420, col = "red")
abline(h = 500, col = "red")
```

```{r arima-forecast-ci, echo=FALSE, message=FALSE, warning=FALSE}
lower <- data.frame(arima_pred) %>%
  dplyr::filter(Point.Forecast >= 420) %>%
  head(1)
upper <- data.frame(arima_pred) %>%
  dplyr::filter(Point.Forecast <= 500) %>%
  tail(1)
level2100 <- data.frame(arima_pred)["Jan 2100", ]
co2_bounds <- rbind(lower, upper, level2100)

data.frame(round(co2_bounds,0)) %>%
  knitr::kable()
```